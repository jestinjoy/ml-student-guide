# **MG4DSEBCA201 -  Introduction to Machine Learning**

## [**Module 1 — Introduction to Machine Learning**](01-intro.md)

- **Introduction**
  - Definition, History, and Applications of Machine Learning  
- **Types of Machine Learning**
  - Supervised Learning  
  - Unsupervised Learning  
  - Semi-Supervised Learning  
  - Reinforcement Learning  
- **Datasets**
  - Labeled and Unlabeled Datasets  
- **Supervised Learning Tasks**
  - Regression vs. Classification  
- **Learning Framework**
  - Training, Validation, and Testing of ML Models  
- **Performance Evaluation Parameters**
  - Confusion Matrix  
  - Accuracy  
  - Precision  
  - Recall  
  - F1 Score  
  - Area Under the Curve (AUC)  

---

## **Module 2 — Supervised and Unsupervised Learning**

### **Supervised Learning**
- **Regression**
  - Linear and Non-Linear Regression  
  - Logistic Regression  
- **Classification**
  - Naïve Bayes  
  - K-Nearest Neighbors (KNN)  
  - Decision Trees (ID3 / CART)  
- **Linear Models**
  - Introduction to Artificial Neural Networks  
  - Perceptron Learning Algorithm  
  - Single-Layer Perceptron  
  - Introduction to Support Vector Machine (SVM) for linearly separable data  

### **Unsupervised Learning**
- **Clustering Algorithms**
  - K-Means  
  - Hierarchical Clustering  
  - DBSCAN  
- **Clustering Validation Measures**

### **Applications and Ethics**
- Ethical Considerations in Machine Learning  
- Case Studies and Real-world Applications  

---

## **Module 3 — Practical Experiments and Implementations**

### **Implementation Tasks**
1. Implement **Linear Regression** on a dataset and visualize the regression line.  
2. Implement **Logistic Regression** on a binary classification dataset and plot the decision boundary.  
3. Implement and evaluate **Decision Tree (ID3/CART)** classifier for a given dataset.  
4. Implement and evaluate the **Naïve Bayes Classifier** on a given dataset.  
5. Implement **K-Means Clustering** on a dataset, visualize, and evaluate the clusters.  
6. Implement **Hierarchical Clustering** and plot the dendrogram.  
7. Implement **DBSCAN Clustering**, visualize, and evaluate the clusters.  
8. Perform **Principal Component Analysis (PCA)** and apply classifiers to compare performance with and without feature reduction.  
9. Build and evaluate a **Random Forest Classifier** using a numerical dataset.  
10. Implement a **Support Vector Machine (SVM)** for linearly separable classes and visualize margins and decision boundaries.  

### **Advanced Tasks**
- Build a **Single-Layer Perceptron Model** to classify **AND**, **OR**, and **XOR** problems (using TensorFlow/Keras) and visualize their decision boundaries. Evaluate performance.  
- Demonstrate the concept of **Boosting** using the **AdaBoost Algorithm**.  

